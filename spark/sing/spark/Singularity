# based on nickjer/singularity-rstudio-spark:latest
# singularity run -B /tmp/logs:/opt/spark/logs -B /tmp/work:/opt/spark/work spark.img --app preprocCMAQ

BootStrap: docker
From: ubuntu:18.04

%labels
  Maintainer Hao Xu
  Spark_Version 2.3.1
  Hadoop_Version 2.7

%help
  This will run Apache Spark

%apprun start
  start-master.sh
  exec start-slave.sh spark://localhost:7077

%apprun stop
  start-master.sh
  exec stop-slaves.sh

%apprun preprocCMAQ
  cd /opt/icees
  exec python runPreprocCMAQ.py localhost ~ "$@"

%runscript
  exec spark-class "$@"

%environment
  export SPARK_HOME=/opt/spark
  export PATH=${SPARK_HOME}/bin:${SPARK_HOME}/sbin:${PATH}

%post
  # Software versions
  export SPARK_VERSION=2.3.1
  export HADOOP_VERSION=2.7

  # Install Spark
  apt-get update
  apt-get install gnupg ca-certificates wget -y
  echo "deb https://dl.bintray.com/sbt/debian /" | tee -a /etc/apt/sources.list.d/sbt.list
  apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 2EE0EA64E40A89B84B2DF73499E82A75642AC823
  apt-get update
  apt-get install sbt openjdk-8-jre sbt -y
  mkdir -p /opt/spark
  wget "http://mirror.cc.columbia.edu/pub/software/apache/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz"
  tar zxvf spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz --strip-components=1 -C /opt/spark
  rm spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz
  git clone https://github.com/xu-hao/datatrans
  cd datatrans/spark
  sbt compile
  cp -r src/main/python /opt/icees

